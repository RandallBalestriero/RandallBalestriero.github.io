<img src="docs/assets/image_magnet.png" class="card-img-top" alt="faces generation">
<div class="card-body">
    <h6 class="card-title">One ICLR 2022 paper</h6>
    <p class="card-text text-center">
        <a href="https://openreview.net/forum?id=r5qumLiYwf9" class="p-1">Link</a>
        <a href="#" data-toggle="modal" data-target="#modalMAGNET" class="p-1">
            Abstract
        </a>
    <div class="modal fade" id="modalMAGNET" tabindex="-1" role="dialog" aria-labelledby="exampleModalLabel"
        aria-hidden="true">
        <div class="modal-dialog" role="document">
            <div class="modal-content">
                <h5 class="modal-title">
                    MaGNET: Uniform Sampling from Deep Generative Network Manifolds Without Retraining
                </h5>
                <div class="modal-body">
                    Deep Generative Networks (DGNs) are extensively employed in Generative Adversarial Networks
                    (GANs), Variational Autoencoders (VAEs), and their variants to approximate the data manifold,
                    and data distribution on that manifold. However, training samples are often obtained based on
                    preferences, costs, or convenience producing artifacts in the empirical data distribution e.g.
                    the large fraction of smiling faces in the CelebA dataset or the large fraction of dark-haired
                    individuals in FFHQ). {\em These inconsistencies will be reproduced when sampling from the
                    trained DGN, which has far-reaching potential implications for fairness, data augmentation,
                    anomaly detection, domain adaptation, and beyond.} In response, we develop a differential
                    geometry based sampler -coined MaGNET- that, given any trained DGN, produces samples that are
                    uniformly distributed on the learned manifold. We prove theoretically and empirically that our
                    technique produces a uniform distribution on the manifold regardless of the training set
                    distribution. We perform a range of experiments on various datasets and DGNs. One of them
                    considers the state-of-the-art StyleGAN2 trained on FFHQ dataset, where uniform sampling via
                    MaGNET increases distribution precision & recall by 4.12% & 3.01% and decreases gender bias by
                    41.2%, without requiring labels or retraining.
                </div>
                <div class="modal-footer text-center">
                    <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
                </div>
            </div>
        </div>
    </div>
    </p>
</div>
<div class="card-footer">
    <small class="text-muted">Last updated: 02/19/2022</small>
</div>